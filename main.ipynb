{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises-MRI-segmentation\n",
    "\n",
    "Coding exercises for appying to the position at the Paris Brain Institute. The base code is taken from the following tutorial: https://colab.research.google.com/github/fepegar/torchio-notebooks/blob/main/notebooks/TorchIO_MONAI_PyTorch_Lightning.ipynb#scrollTo=QixbF3koO99H. \n",
    "\n",
    "TODO: write an introduction to the problem, the type of data that is going to be used, the number of labels, training strategy, etc..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "- Write a training code for a similar training as in the tutorial, but without the\n",
    "pytorch_lightning library.\n",
    "- Make one script with a command line for training.\n",
    "- In the training loop use the automatic mixed precision from Pytorch (with autocast and\n",
    "GradScaler) in order to train with FP16 precision instead of the default FP32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra imports\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import monai\n",
    "from utils.plotting import plot_image_label\n",
    "from utils.training_funcs import training_loop\n",
    "from utils.MedicalDecathlonClass import MedicalDecathlonDataModule\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# hyperparameters\n",
    "config = {\n",
    "    \"task\": \"Task04_Hippocampus\",\n",
    "    \"google_id\": \"1RzPB1_bqzQhlWvU-YGvZzhx2omcDh38C\",\n",
    "    \"batch_size\": 16,\n",
    "    \"train_val_ratio\": 0.8,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 1e-2,\n",
    "    \"early_stopping\": 10,  # -1 to disable, else insert patience\n",
    "    \"mixed_precision\": False,\n",
    "    \"Nit\": 8,  # number of iterations for the training loop, None if you want to do all\n",
    "    \"train_from_checkpoint\": None,  # None to train from scratch, else insert path to the model weights\n",
    "    \"fine_tune\": False,  # True to fine-tune the model, else False to train from scratch\n",
    "    \"best_models_dir\": \"best_models\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    config[\"early_stopping\"] == -1 or config[\"early_stopping\"] > 0\n",
    "), \"early_stopping must be -1 or > 0\"\n",
    "assert (\n",
    "    config[\"train_val_ratio\"] > 0 and config[\"train_val_ratio\"] < 1\n",
    "), \"train_val_ratio must be > 0 and < 1\"\n",
    "assert config[\"batch_size\"] > 0, \"batch_size must be > 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data download & preparation\n",
    "data = MedicalDecathlonDataModule(\n",
    "    task=config[\"task\"],\n",
    "    google_id=config[\"google_id\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    train_val_ratio=config[\"train_val_ratio\"],\n",
    ")\n",
    "\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "\n",
    "train_data_loader = data.train_dataloader()\n",
    "val_data_loader = data.val_dataloader()\n",
    "test_data_loader = data.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a training example\n",
    "batch = next(iter(train_data_loader))\n",
    "\n",
    "batch_image = batch[\"image\"][\"data\"]\n",
    "batch_label = batch[\"label\"][\"data\"]\n",
    "\n",
    "print(f\"The shape of the data is {batch_image.shape}\")\n",
    "\n",
    "plot_image_label(batch_image, batch_label, slice_idx=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net model from monai\n",
    "model = monai.networks.nets.UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(8, 16, 32, 64),\n",
    "    strides=(2, 2, 2),\n",
    ")\n",
    "\n",
    "criterion = monai.losses.DiceCELoss(softmax=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loop(\n",
    "    train_data_loader=train_data_loader,\n",
    "    val_data_loader=val_data_loader,\n",
    "    device=device,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=config[\"epochs\"],\n",
    "    early_stopping=config[\"early_stopping\"],\n",
    "    train_from_checkpoint=config[\"train_from_checkpoint\"],\n",
    "    fine_tune=config[\"fine_tune\"],\n",
    "    best_models_dir=config[\"best_models_dir\"],\n",
    "    mixed_precision=config[\"mixed_precision\"],\n",
    "    Nit=config[\"Nit\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning thoughts\n",
    "\n",
    "To understand how to fine tune the model, I decided to print the model structure and shapes of the parameters it is made of. Then I saw that the last 2 sets of parameters corresponded to the last ConvTranspose3d and the corresponding bias, with shapes `torch.Size([16, 3, 3, 3, 3])` and `torch.Size([3])`. \n",
    "\n",
    "Hence I decided to freeze all the other weights and only keep thos for the fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in list(model.parameters()):\n",
    "    print(param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ParisBI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
